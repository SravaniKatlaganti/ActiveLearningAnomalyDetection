{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'Breakout'\n",
    "num_episodes = 25 #use them all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialise kaggle.\n",
      "WARNING: failed to find module: moviepy.editor\n",
      "USING DEVICE: cpu\n",
      "aad\n",
      "aad.clean\n",
      "aad.clean.BeamRider\n",
      "aad.clean.BeamRider.action\n",
      "aad.clean.BeamRider.state\n",
      "aad.clean.Breakout\n",
      "aad.clean.Breakout.action\n",
      "aad.clean.Breakout.state\n",
      "aad.clean.Enduro\n",
      "aad.clean.Enduro.action\n",
      "aad.clean.Enduro.state\n",
      "aad.clean.Pong\n",
      "aad.clean.Pong.action\n",
      "aad.clean.Pong.state\n",
      "aad.clean.Qbert\n",
      "aad.clean.Qbert.action\n",
      "aad.clean.Qbert.state\n",
      "aad.clean.Seaquest\n",
      "aad.clean.Seaquest.action\n",
      "aad.clean.Seaquest.state\n",
      "aad.clean.SpaceInvaders\n",
      "aad.clean.SpaceInvaders.action\n",
      "aad.clean.SpaceInvaders.state\n",
      "aad.raw\n",
      "aad.raw.BeamRider\n",
      "aad.raw.BeamRider.action\n",
      "aad.raw.BeamRider.state\n",
      "aad.raw.Breakout\n",
      "aad.raw.Breakout.action\n",
      "aad.raw.Breakout.state\n",
      "aad.raw.Enduro\n",
      "aad.raw.Enduro.action\n",
      "aad.raw.Enduro.state\n",
      "aad.raw.Pong\n",
      "aad.raw.Pong.action\n",
      "aad.raw.Pong.state\n",
      "aad.raw.Qbert\n",
      "aad.raw.Qbert.action\n",
      "aad.raw.Qbert.state\n",
      "aad.raw.Seaquest\n",
      "aad.raw.Seaquest.action\n",
      "aad.raw.Seaquest.state\n",
      "aad.raw.SpaceInvaders\n",
      "aad.raw.SpaceInvaders.action\n",
      "aad.raw.SpaceInvaders.state\n",
      "aad.anomaly\n",
      "aad.anomaly.BeamRider\n",
      "aad.anomaly.BeamRider.action\n",
      "aad.anomaly.BeamRider.label\n",
      "aad.anomaly.BeamRider.state\n",
      "aad.anomaly.BeamRider.tlabel\n",
      "aad.anomaly.Breakout\n",
      "aad.anomaly.Breakout.action\n",
      "aad.anomaly.Breakout.label\n",
      "aad.anomaly.Breakout.state\n",
      "aad.anomaly.Breakout.tlabel\n",
      "aad.anomaly.Enduro\n",
      "aad.anomaly.Enduro.action\n",
      "aad.anomaly.Enduro.label\n",
      "aad.anomaly.Enduro.state\n",
      "aad.anomaly.Enduro.tlabel\n",
      "aad.anomaly.Pong\n",
      "aad.anomaly.Pong.action\n",
      "aad.anomaly.Pong.label\n",
      "aad.anomaly.Pong.state\n",
      "aad.anomaly.Pong.tlabel\n",
      "aad.anomaly.Qbert\n",
      "aad.anomaly.Qbert.action\n",
      "aad.anomaly.Qbert.label\n",
      "aad.anomaly.Qbert.state\n",
      "aad.anomaly.Qbert.tlabel\n",
      "aad.anomaly.Seaquest\n",
      "aad.anomaly.Seaquest.action\n",
      "aad.anomaly.Seaquest.label\n",
      "aad.anomaly.Seaquest.state\n",
      "aad.anomaly.Seaquest.tlabel\n",
      "aad.anomaly.SpaceInvaders\n",
      "aad.anomaly.SpaceInvaders.action\n",
      "aad.anomaly.SpaceInvaders.label\n",
      "aad.anomaly.SpaceInvaders.state\n",
      "aad.anomaly.SpaceInvaders.tlabel\n"
     ]
    }
   ],
   "source": [
    "import anomapy.train.sssn as sssn\n",
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import numpy as np\n",
    "\n",
    "def distance(model, episode):\n",
    "    z, d = sssn.distance(model, episode)\n",
    "    return tu.to_numpy(z), tu.to_numpy(d)\n",
    "    \n",
    "def plot_latent(model, episode):\n",
    "    z = tu.to_numpy(sssn.encode(model, episode))\n",
    "    print(z)\n",
    "    images = T.HWC(tu.to_numpy(episode))\n",
    "    return J.scatter_image(z[:,0], z[:,1], images, scatter_colour='blue', line_colour='#b9d1fa', scale=1.5)\n",
    "\n",
    "def order_by(model, episode):\n",
    "    d, z = distance(model, episode)\n",
    "    images = T.HWC(tu.to_numpy(episode))\n",
    "    i = np.argsort(-d)\n",
    "    return d[i], images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset aad.raw.Breakout.state...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0ef1e7c3c44b9c843862edc71b49d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 torch.Size([2867, 3, 210, 160])\n",
      "episode: 1 torch.Size([2359, 3, 210, 160])\n",
      "episode: 2 torch.Size([4901, 3, 210, 160])\n",
      "episode: 3 torch.Size([2200, 3, 210, 160])\n",
      "episode: 4 torch.Size([2236, 3, 210, 160])\n",
      "episode: 5 torch.Size([2022, 3, 210, 160])\n",
      "episode: 6 torch.Size([2461, 3, 210, 160])\n",
      "episode: 7 torch.Size([3422, 3, 210, 160])\n",
      "episode: 8 torch.Size([2171, 3, 210, 160])\n",
      "episode: 9 torch.Size([2036, 3, 210, 160])\n",
      "episode: 10 torch.Size([2589, 3, 210, 160])\n",
      "episode: 11 torch.Size([2343, 3, 210, 160])\n",
      "episode: 12 torch.Size([1767, 3, 210, 160])\n",
      "episode: 13 torch.Size([2228, 3, 210, 160])\n",
      "episode: 14 torch.Size([1772, 3, 210, 160])\n",
      "episode: 15 torch.Size([2546, 3, 210, 160])\n",
      "episode: 16 torch.Size([2984, 3, 210, 160])\n",
      "episode: 17 torch.Size([1329, 3, 210, 160])\n",
      "episode: 18 torch.Size([2441, 3, 210, 160])\n",
      "episode: 19 torch.Size([1783, 3, 210, 160])\n",
      "episode: 20 torch.Size([2105, 3, 210, 160])\n",
      "episode: 21 torch.Size([2239, 3, 210, 160])\n",
      "episode: 22 torch.Size([1946, 3, 210, 160])\n",
      "episode: 23 torch.Size([2034, 3, 210, 160])\n",
      "episode: 24 torch.Size([3799, 3, 210, 160])\n",
      "60580\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "dataset = datasets.dataset('aad.raw.{0}'.format(env))\n",
    "dataset.state.transform.to_float().CHW().torch()\n",
    "episodes = [x for x in dataset.state.load(num_episodes)]\n",
    "for i,e in enumerate(episodes):\n",
    "    print(\"episode:\", i, e.shape)\n",
    "    \n",
    "print(np.sum([e.shape[0] for e in episodes]))\n",
    "    \n",
    "episode_test = episodes[-1]\n",
    "episodes = episodes[:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "import pyworld.toolkit.tools.wbutils as wbu\n",
    "import pyworld.toolkit.tools.fileutils as fu\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "\n",
    "import anomapy.train.sssn as sssn\n",
    "\n",
    "CONFIG = sssn.default_config()\n",
    "CONFIG.update(dataset.meta.to_dict())\n",
    "CONFIG['latent_shape'] = 256\n",
    "CONFIG['epochs'] = 1\n",
    "CONFIG['batch_size'] = 128\n",
    "CONFIG['total_states'] = sum([e.shape[0] for e in episodes])\n",
    "CONFIG['episodes'] = len(episodes)\n",
    "CONFIG = SimpleNamespace(**CONFIG)\n",
    "\n",
    "print(CONFIG)\n",
    "\n",
    "DRYRUN = True\n",
    "PROJECT = \"anomaly-detection\"\n",
    "RUN_ID = \"{0}-{1}-{2}\".format(CONFIG.model, CONFIG.name, fu.file_datetime())\n",
    "RUN_TAGS = [CONFIG.model, CONFIG.name]\n",
    "\n",
    "wbu.dryrun(DRYRUN)\n",
    "\n",
    "optimiser = sssn.new(dryrun=DRYRUN, **CONFIG.__dict__)\n",
    "model = optimiser.model\n",
    "\n",
    "wb = wbu.WB(PROJECT, model, id=RUN_ID, tags=RUN_TAGS, config=CONFIG.__dict__)\n",
    "#loss_plot = J.dynamic_plot(update_after=10)\n",
    "\n",
    "#z = tu.to_numpy(sssn.encode(model, episodes[0]))\n",
    "#plot = J.plot(z[:,0], z[:,1], mode=J.line_mode.both)\n",
    "\n",
    "with wb:\n",
    "    for i in range(CONFIG.epochs):\n",
    "        print(\"---- epoch: \", i)\n",
    "        for episode in episodes:\n",
    "            for loss in sssn.epoch(optimiser, episode, CONFIG.batch_size):\n",
    "                pass #loss_plot.update(None, loss['loss'])\n",
    "            #z = tu.to_numpy(sssn.encode(model, episodes[0]))\n",
    "            #plot.set_data(z[:,0], z[:,1])\n",
    "            print(\"loss:\", optimiser.cma())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialise kaggle.\n",
      "WARNING: failed to find module: moviepy.editor\n",
      "USING DEVICE: cpu\n",
      "aad\n",
      "aad.clean\n",
      "aad.clean.BeamRider\n",
      "aad.clean.BeamRider.action\n",
      "aad.clean.BeamRider.state\n",
      "aad.clean.Breakout\n",
      "aad.clean.Breakout.action\n",
      "aad.clean.Breakout.state\n",
      "aad.clean.Enduro\n",
      "aad.clean.Enduro.action\n",
      "aad.clean.Enduro.state\n",
      "aad.clean.Pong\n",
      "aad.clean.Pong.action\n",
      "aad.clean.Pong.state\n",
      "aad.clean.Qbert\n",
      "aad.clean.Qbert.action\n",
      "aad.clean.Qbert.state\n",
      "aad.clean.Seaquest\n",
      "aad.clean.Seaquest.action\n",
      "aad.clean.Seaquest.state\n",
      "aad.clean.SpaceInvaders\n",
      "aad.clean.SpaceInvaders.action\n",
      "aad.clean.SpaceInvaders.state\n",
      "aad.raw\n",
      "aad.raw.BeamRider\n",
      "aad.raw.BeamRider.action\n",
      "aad.raw.BeamRider.state\n",
      "aad.raw.Breakout\n",
      "aad.raw.Breakout.action\n",
      "aad.raw.Breakout.state\n",
      "aad.raw.Enduro\n",
      "aad.raw.Enduro.action\n",
      "aad.raw.Enduro.state\n",
      "aad.raw.Pong\n",
      "aad.raw.Pong.action\n",
      "aad.raw.Pong.state\n",
      "aad.raw.Qbert\n",
      "aad.raw.Qbert.action\n",
      "aad.raw.Qbert.state\n",
      "aad.raw.Seaquest\n",
      "aad.raw.Seaquest.action\n",
      "aad.raw.Seaquest.state\n",
      "aad.raw.SpaceInvaders\n",
      "aad.raw.SpaceInvaders.action\n",
      "aad.raw.SpaceInvaders.state\n",
      "aad.anomaly\n",
      "aad.anomaly.BeamRider\n",
      "aad.anomaly.BeamRider.action\n",
      "aad.anomaly.BeamRider.label\n",
      "aad.anomaly.BeamRider.state\n",
      "aad.anomaly.BeamRider.tlabel\n",
      "aad.anomaly.Breakout\n",
      "aad.anomaly.Breakout.action\n",
      "aad.anomaly.Breakout.label\n",
      "aad.anomaly.Breakout.state\n",
      "aad.anomaly.Breakout.tlabel\n",
      "aad.anomaly.Enduro\n",
      "aad.anomaly.Enduro.action\n",
      "aad.anomaly.Enduro.label\n",
      "aad.anomaly.Enduro.state\n",
      "aad.anomaly.Enduro.tlabel\n",
      "aad.anomaly.Pong\n",
      "aad.anomaly.Pong.action\n",
      "aad.anomaly.Pong.label\n",
      "aad.anomaly.Pong.state\n",
      "aad.anomaly.Pong.tlabel\n",
      "aad.anomaly.Qbert\n",
      "aad.anomaly.Qbert.action\n",
      "aad.anomaly.Qbert.label\n",
      "aad.anomaly.Qbert.state\n",
      "aad.anomaly.Qbert.tlabel\n",
      "aad.anomaly.Seaquest\n",
      "aad.anomaly.Seaquest.action\n",
      "aad.anomaly.Seaquest.label\n",
      "aad.anomaly.Seaquest.state\n",
      "aad.anomaly.Seaquest.tlabel\n",
      "aad.anomaly.SpaceInvaders\n",
      "aad.anomaly.SpaceInvaders.action\n",
      "aad.anomaly.SpaceInvaders.label\n",
      "aad.anomaly.SpaceInvaders.state\n",
      "aad.anomaly.SpaceInvaders.tlabel\n",
      "offline-run-20230417_141950-sssn-Breakout-20230417141946\n",
      " -- found local run at c:\\Users\\katla\\Downloads\\S3N\\wandb\\offline-run-20230417_141950-sssn-Breakout-20230417141946\n",
      " -- failed to find wandb meta data...\n",
      " -- found config file.\n",
      " -- found 1 model(s): \n",
      " ---- model.pt\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "import anomapy.train.sssn as sssn\n",
    "import pyworld.toolkit.tools.wbutils as wbu\n",
    "\n",
    "\n",
    "def distance(model, episode):\n",
    "    z, d = sssn.distance(model, episode)\n",
    "    return tu.to_numpy(z), tu.to_numpy(d)\n",
    "\n",
    "\n",
    "env = \"Breakout\"\n",
    "dryruns = sorted([r for r in wbu.dryruns() if env in r])\n",
    "print(dryruns[-1])\n",
    "\n",
    "models, config = wbu.load(dryruns[-1]) #load the most recently trained model\n",
    "model = models['model.pt'].load(sssn.model(**config))\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset aad.anomaly.Breakout.state...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1fa30a5c3c4bc9aead6b16ae55eafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset aad.anomaly.Breakout.label...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef63c3b9e3443a7a679593836ca1957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "dataset = datasets.dataset('aad.anomaly.{0}'.format(env))\n",
    "dataset.state.transform.to_float().CHW().torch()\n",
    "anoms = [(a,e[0]) for a,e in dataset.meta.anomaly.items()]\n",
    "a_episodes = [d for d in dataset.state.load_files(*[e[1] for e in anoms])]\n",
    "a_labels = [d for d in dataset.label.load_files(*[e[1] for e in anoms])]\n",
    "a_tlabels = [np.logical_or(l[:-1], l[1:]).astype(np.uint8) for l in a_labels] #transition labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score, precision_score,f1_score\n",
    "from sklearn.metrics import auc, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.visutils.plot as vplot\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import pyworld.toolkit.tools.fileutils as fu\n",
    "import pyworld.toolkit.tools.datautils as du\n",
    "\n",
    "\n",
    "import numpy as n\n",
    "from pprint import pprint\n",
    "\n",
    "def roc(label, score):\n",
    "    assert label.shape[0] == score.shape[0]\n",
    "    fpr, tpr, _ = roc_curve(label, score)\n",
    "   \n",
    "    return fpr, tpr\n",
    "\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = {}\n",
    "avg_prec = {}\n",
    "legend = []\n",
    "for i in range(len(a_episodes[:-1])):\n",
    "    episode = a_episodes[i]\n",
    "    anomaly = anoms[i][0]\n",
    "    label = a_tlabels[i]\n",
    "\n",
    "    z, score = distance(model, episode)\n",
    "    latent_space = tu.to_numpy(z)\n",
    "    score = du.normalise(score)\n",
    "    fpr, tpr, _ = roc_curve(label, score)\n",
    "    aucs[anomaly] = auc(fpr, tpr)\n",
    "    prec, rec, _ = precision_recall_curve(label,score)\n",
    "    avg_prec[anomaly] = average_precision_score(label,score)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    legend.append(anomaly)\n",
    "    print(\"\\nEpisode\", i)\n",
    "    print(anomaly)\n",
    "    print(\"\\nAUC:\\n\",auc(fpr, tpr))\n",
    "    print(\"\\nFPR:\\n\",fpr)\n",
    "    print(\"\\nTPR:\\n\",tpr)\n",
    "    #print(\"\\nAverage Precision Scores\\n\",average_precision_score(label,score))\n",
    "    \n",
    "    #print(\"\\nConfusion Matrix:\\n\",confusion_matrix(label,score))\n",
    "    #print(\"\\nRecall\\n\",recall_score(label,score))\n",
    "    #print(\"\\nPrecision\\n\",precision_score(label,score))\n",
    "    #print(\"\\nF1Score\\n\",f1_score(label,score))\n",
    "\n",
    "\n",
    "print(\"\\n\\nAUCs\\n\")    \n",
    "pprint(aucs)\n",
    "# legend[0] = 'flicker'\n",
    "# legend[1] = 'visual artefact'\n",
    "# legend = [l.replace('_', ' ') for l in legend]\n",
    "# print(legend)\n",
    "\n",
    "# plot = J.plot(fprs, tprs, legend=legend, show=False)\n",
    "# plot.fig.update_layout(showlegend=True, autosize=False, width=500, height=400, margin=dict(l=5,b=5,r=5,t=5))\n",
    "# plot.fig.update_layout(dict(legend=dict(xanchor='center', x=0.5, orientation='h')))\n",
    "\n",
    "#path = \"/home/ben/Downloads/rocs/\"\n",
    "#plot.fig.write_image(path + \"{0}.png\".format(env))\n",
    "#fu.save(path + \"{0}.json\".format(env), aucs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 0\n",
      "block\n",
      "\n",
      "Avg Precision Score:\n",
      " 0.9155208946093999\n",
      "\n",
      "Precision:\n",
      " [0.19008264 0.19025735 0.19043238 ... 1.         1.         1.        ]\n",
      "\n",
      "Recall:\n",
      " [1.         1.         1.         ... 0.00966184 0.00483092 0.        ]\n",
      "\n",
      "Episode 1\n",
      "flicker\n",
      "\n",
      "Avg Precision Score:\n",
      " 0.5866166247763965\n",
      "\n",
      "Precision:\n",
      " [0.17974322 0.09803922 0.09811617 ... 1.         1.         1.        ]\n",
      "\n",
      "Recall:\n",
      " [1.         0.49603175 0.49603175 ... 0.00793651 0.00396825 0.        ]\n",
      "\n",
      "Episode 2\n",
      "freeze\n",
      "\n",
      "Avg Precision Score:\n",
      " 0.3356803293111978\n",
      "\n",
      "Precision:\n",
      " [0.36429872 0.05013674 0.05018248 ... 0.         0.         1.        ]\n",
      "\n",
      "Recall:\n",
      " [1.         0.09166667 0.09166667 ... 0.         0.         0.        ]\n",
      "\n",
      "Episode 3\n",
      "freeze_skip\n",
      "\n",
      "Avg Precision Score:\n",
      " 0.3059837993465002\n",
      "\n",
      "Precision:\n",
      " [0.27404844 0.04204753 0.042086   ... 1.         1.         1.        ]\n",
      "\n",
      "Recall:\n",
      " [1.         0.11616162 0.11616162 ... 0.00505051 0.00252525 0.        ]\n",
      "\n",
      "Episode 4\n",
      "split_horizontal\n",
      "\n",
      "Avg Precision Score:\n",
      " 0.867548946697728\n",
      "\n",
      "Precision:\n",
      " [0.09558824 0.0958231  0.09594096 0.09605911 0.09617756 0.0962963\n",
      " 0.09641533 0.09653465 0.09665428 0.09677419 0.09689441 0.09701493\n",
      " 0.09713574 0.09725686 0.09737828 0.0975     0.09762203 0.09774436\n",
      " 0.097867   0.09798995 0.09811321 0.09823678 0.09836066 0.09848485\n",
      " 0.09860936 0.09873418 0.09885932 0.09898477 0.09911055 0.09923664\n",
      " 0.09936306 0.0994898  0.09961686 0.09974425 0.09987196 0.1\n",
      " 0.10012837 0.10025707 0.1003861  0.10051546 0.10064516 0.10077519\n",
      " 0.10090556 0.10103627 0.10116732 0.1012987  0.10143043 0.1015625\n",
      " 0.10169492 0.10182768 0.10196078 0.10209424 0.10222805 0.1023622\n",
      " 0.10249671 0.10263158 0.1027668  0.10290237 0.10303831 0.1031746\n",
      " 0.10331126 0.10344828 0.10358566 0.1037234  0.10386152 0.104\n",
      " 0.10413885 0.10427807 0.10441767 0.10455764 0.10469799 0.10483871\n",
      " 0.10497981 0.10512129 0.10526316 0.10540541 0.10554804 0.10569106\n",
      " 0.10583446 0.10597826 0.10612245 0.10626703 0.10641201 0.10655738\n",
      " 0.10670315 0.10684932 0.10699588 0.10714286 0.10729023 0.10743802\n",
      " 0.10758621 0.10773481 0.10788382 0.10803324 0.10818308 0.10833333\n",
      " 0.10848401 0.1086351  0.10878661 0.10893855 0.10909091 0.1092437\n",
      " 0.10939691 0.10955056 0.10970464 0.10985915 0.1100141  0.11016949\n",
      " 0.11032532 0.11048159 0.1106383  0.11079545 0.11095306 0.11111111\n",
      " 0.11126961 0.11142857 0.11158798 0.11174785 0.11190818 0.11206897\n",
      " 0.11223022 0.11239193 0.11255411 0.11271676 0.11287988 0.11304348\n",
      " 0.11320755 0.11337209 0.11353712 0.11370262 0.11386861 0.11403509\n",
      " 0.11420205 0.1143695  0.11453744 0.11470588 0.11487482 0.11504425\n",
      " 0.11521418 0.11538462 0.11555556 0.115727   0.11589896 0.11607143\n",
      " 0.11624441 0.11641791 0.11659193 0.11676647 0.11694153 0.11711712\n",
      " 0.11729323 0.11746988 0.11764706 0.11782477 0.11800303 0.11818182\n",
      " 0.11836115 0.11854103 0.11872146 0.11890244 0.11908397 0.11926606\n",
      " 0.1194487  0.1196319  0.11981567 0.12       0.1201849  0.12037037\n",
      " 0.12055641 0.12074303 0.12093023 0.12111801 0.12130638 0.12149533\n",
      " 0.12168487 0.121875   0.12206573 0.12225705 0.12244898 0.12264151\n",
      " 0.12283465 0.12302839 0.12322275 0.12341772 0.12361331 0.12380952\n",
      " 0.12400636 0.12420382 0.12440191 0.12460064 0.1248     0.125\n",
      " 0.12520064 0.12540193 0.12560386 0.12580645 0.12600969 0.12621359\n",
      " 0.12641815 0.12662338 0.12682927 0.12703583 0.12724307 0.12745098\n",
      " 0.12765957 0.12622951 0.12643678 0.12664474 0.12685338 0.12706271\n",
      " 0.12727273 0.12748344 0.12769486 0.12790698 0.1281198  0.12833333\n",
      " 0.12854758 0.12876254 0.12897822 0.12919463 0.12941176 0.12962963\n",
      " 0.12984823 0.13006757 0.13028765 0.13050847 0.13073005 0.13095238\n",
      " 0.13117547 0.13139932 0.13162393 0.13184932 0.13207547 0.13230241\n",
      " 0.13253012 0.13275862 0.13298791 0.13321799 0.13344887 0.13368056\n",
      " 0.13391304 0.13414634 0.13438045 0.13461538 0.13485114 0.13508772\n",
      " 0.13532513 0.13556338 0.13580247 0.1360424  0.13628319 0.13652482\n",
      " 0.13676732 0.13701068 0.1372549  0.1375     0.13774597 0.13799283\n",
      " 0.13824057 0.13848921 0.13873874 0.13898917 0.13924051 0.13949275\n",
      " 0.13974592 0.14       0.14025501 0.14051095 0.14076782 0.14102564\n",
      " 0.1412844  0.14154412 0.14180479 0.14206642 0.14232902 0.14259259\n",
      " 0.14285714 0.14312268 0.1433892  0.14365672 0.14392523 0.14419476\n",
      " 0.14446529 0.14473684 0.14500942 0.14528302 0.14555766 0.14583333\n",
      " 0.14611006 0.14638783 0.14666667 0.14694656 0.14722753 0.14750958\n",
      " 0.14779271 0.14807692 0.14836224 0.14864865 0.14700193 0.14728682\n",
      " 0.14757282 0.14785992 0.14814815 0.1484375  0.14872798 0.14901961\n",
      " 0.14931238 0.1496063  0.14990138 0.15019763 0.15049505 0.15079365\n",
      " 0.15109344 0.15139442 0.15169661 0.152      0.15230461 0.15261044\n",
      " 0.15291751 0.15322581 0.15353535 0.15384615 0.15415822 0.15447154\n",
      " 0.15478615 0.15510204 0.15541922 0.1557377  0.15605749 0.15432099\n",
      " 0.15463918 0.15495868 0.1552795  0.15560166 0.15592516 0.15625\n",
      " 0.1565762  0.15690377 0.1572327  0.15756303 0.15789474 0.15822785\n",
      " 0.15856237 0.15889831 0.15923567 0.15957447 0.15991471 0.16025641\n",
      " 0.16059957 0.16094421 0.16129032 0.16163793 0.16198704 0.16233766\n",
      " 0.1626898  0.16304348 0.16339869 0.16375546 0.16411379 0.16447368\n",
      " 0.16483516 0.16519824 0.16556291 0.1659292  0.16629712 0.16666667\n",
      " 0.16703786 0.16741071 0.16778523 0.16816143 0.16853933 0.16891892\n",
      " 0.16930023 0.16968326 0.17006803 0.17045455 0.17084282 0.17123288\n",
      " 0.17162471 0.17201835 0.17241379 0.17281106 0.17321016 0.17361111\n",
      " 0.17401392 0.1744186  0.17482517 0.17523364 0.17564403 0.17605634\n",
      " 0.17647059 0.17688679 0.17730496 0.17535545 0.17577197 0.17619048\n",
      " 0.17661098 0.17703349 0.17745803 0.17788462 0.17831325 0.17874396\n",
      " 0.17917676 0.17961165 0.18004866 0.1804878  0.1809291  0.18137255\n",
      " 0.18181818 0.18226601 0.18271605 0.18316832 0.18362283 0.1840796\n",
      " 0.18453865 0.185      0.18546366 0.18592965 0.18639798 0.18686869\n",
      " 0.18734177 0.18781726 0.18829517 0.18877551 0.18925831 0.18974359\n",
      " 0.19023136 0.19072165 0.19121447 0.19170984 0.19220779 0.19270833\n",
      " 0.19321149 0.19371728 0.19422572 0.19473684 0.19525066 0.1957672\n",
      " 0.19628647 0.19680851 0.19733333 0.19786096 0.19839142 0.19892473\n",
      " 0.19946092 0.2        0.20054201 0.20108696 0.20163488 0.20218579\n",
      " 0.20273973 0.2032967  0.20385675 0.20441989 0.20498615 0.20555556\n",
      " 0.20612813 0.20670391 0.20728291 0.20786517 0.2084507  0.20903955\n",
      " 0.20963173 0.21022727 0.21082621 0.21142857 0.21203438 0.21264368\n",
      " 0.21325648 0.21387283 0.21449275 0.21511628 0.21574344 0.21637427\n",
      " 0.2170088  0.21764706 0.21828909 0.21893491 0.21958457 0.2202381\n",
      " 0.22089552 0.22155689 0.22222222 0.22289157 0.22356495 0.22424242\n",
      " 0.22492401 0.22560976 0.22629969 0.22699387 0.22769231 0.22839506\n",
      " 0.22910217 0.22981366 0.2305296  0.23125    0.23197492 0.2327044\n",
      " 0.23343849 0.23417722 0.23174603 0.23248408 0.23322684 0.23397436\n",
      " 0.23472669 0.23548387 0.23624595 0.23701299 0.23778502 0.23856209\n",
      " 0.23934426 0.24013158 0.24092409 0.24172185 0.24252492 0.24333333\n",
      " 0.24414716 0.24496644 0.24579125 0.24662162 0.24745763 0.24829932\n",
      " 0.24914676 0.25       0.25085911 0.25172414 0.25259516 0.25347222\n",
      " 0.2543554  0.25524476 0.25614035 0.25704225 0.25795053 0.25886525\n",
      " 0.25978648 0.26071429 0.26164875 0.26258993 0.26353791 0.26449275\n",
      " 0.26545455 0.26642336 0.26739927 0.26838235 0.26937269 0.27037037\n",
      " 0.27137546 0.27238806 0.27340824 0.27443609 0.2754717  0.27651515\n",
      " 0.27756654 0.27862595 0.27969349 0.28076923 0.28185328 0.27906977\n",
      " 0.28015564 0.28125    0.28235294 0.28346457 0.28458498 0.28571429\n",
      " 0.28685259 0.288      0.28915663 0.29032258 0.29149798 0.29268293\n",
      " 0.29387755 0.29508197 0.2962963  0.29752066 0.29875519 0.3\n",
      " 0.30125523 0.30252101 0.30379747 0.30508475 0.30638298 0.30769231\n",
      " 0.30901288 0.31034483 0.31168831 0.31304348 0.31441048 0.31578947\n",
      " 0.31718062 0.31858407 0.32       0.32142857 0.32286996 0.32432432\n",
      " 0.32579186 0.32727273 0.32876712 0.33027523 0.33179724 0.33333333\n",
      " 0.33488372 0.3364486  0.33802817 0.33962264 0.34123223 0.34285714\n",
      " 0.34449761 0.34615385 0.34782609 0.34951456 0.35121951 0.35294118\n",
      " 0.3546798  0.35643564 0.35820896 0.36       0.36180905 0.36363636\n",
      " 0.36548223 0.36734694 0.36923077 0.37113402 0.37305699 0.375\n",
      " 0.37696335 0.37894737 0.38095238 0.37765957 0.37967914 0.38172043\n",
      " 0.38378378 0.38586957 0.38797814 0.39010989 0.38674033 0.38888889\n",
      " 0.39106145 0.39325843 0.39548023 0.39772727 0.4        0.40229885\n",
      " 0.39884393 0.40116279 0.40350877 0.40588235 0.40828402 0.41071429\n",
      " 0.41317365 0.41566265 0.41818182 0.42073171 0.41717791 0.41975309\n",
      " 0.42236025 0.41875    0.42138365 0.42405063 0.42675159 0.42948718\n",
      " 0.43225806 0.43506494 0.4379085  0.44078947 0.44370861 0.44666667\n",
      " 0.44966443 0.4527027  0.45578231 0.45890411 0.46206897 0.46527778\n",
      " 0.46153846 0.46478873 0.46808511 0.47142857 0.47482014 0.47826087\n",
      " 0.48175182 0.48529412 0.48888889 0.49253731 0.4962406  0.5\n",
      " 0.50381679 0.50769231 0.51162791 0.515625   0.51968504 0.52380952\n",
      " 0.52       0.52419355 0.52845528 0.53278689 0.53719008 0.54166667\n",
      " 0.54621849 0.55084746 0.55555556 0.56034483 0.56521739 0.57017544\n",
      " 0.57522124 0.58035714 0.58558559 0.59090909 0.59633028 0.60185185\n",
      " 0.59813084 0.59433962 0.59047619 0.59615385 0.60194175 0.60784314\n",
      " 0.61386139 0.62       0.62626263 0.63265306 0.63917526 0.64583333\n",
      " 0.65263158 0.65957447 0.66666667 0.67391304 0.68131868 0.68888889\n",
      " 0.69662921 0.70454545 0.71264368 0.72093023 0.72941176 0.73809524\n",
      " 0.74698795 0.75609756 0.7654321  0.775      0.7721519  0.78205128\n",
      " 0.79220779 0.80263158 0.81333333 0.82432432 0.83561644 0.84722222\n",
      " 0.85915493 0.87142857 0.88405797 0.89705882 0.91044776 0.92424242\n",
      " 0.93846154 0.953125   0.96825397 0.96774194 0.98360656 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n",
      "\n",
      "Recall:\n",
      " [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949 0.98717949\n",
      " 0.98717949 0.98717949 0.98717949 0.98717949 0.97435897 0.97435897\n",
      " 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897\n",
      " 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897\n",
      " 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897\n",
      " 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897\n",
      " 0.97435897 0.97435897 0.97435897 0.97435897 0.97435897 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846 0.96153846\n",
      " 0.96153846 0.96153846 0.96153846 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795 0.94871795\n",
      " 0.94871795 0.94871795 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744\n",
      " 0.93589744 0.93589744 0.93589744 0.93589744 0.93589744 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.91025641 0.91025641 0.91025641\n",
      " 0.91025641 0.91025641 0.91025641 0.91025641 0.8974359  0.8974359\n",
      " 0.8974359  0.8974359  0.8974359  0.8974359  0.8974359  0.8974359\n",
      " 0.88461538 0.88461538 0.88461538 0.88461538 0.88461538 0.88461538\n",
      " 0.88461538 0.88461538 0.88461538 0.88461538 0.87179487 0.87179487\n",
      " 0.87179487 0.85897436 0.85897436 0.85897436 0.85897436 0.85897436\n",
      " 0.85897436 0.85897436 0.85897436 0.85897436 0.85897436 0.85897436\n",
      " 0.85897436 0.85897436 0.85897436 0.85897436 0.85897436 0.85897436\n",
      " 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385\n",
      " 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385\n",
      " 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385 0.84615385\n",
      " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
      " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
      " 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n",
      " 0.82051282 0.80769231 0.79487179 0.79487179 0.79487179 0.79487179\n",
      " 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179\n",
      " 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179\n",
      " 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179 0.79487179\n",
      " 0.79487179 0.79487179 0.79487179 0.79487179 0.78205128 0.78205128\n",
      " 0.78205128 0.78205128 0.78205128 0.78205128 0.78205128 0.78205128\n",
      " 0.78205128 0.78205128 0.78205128 0.78205128 0.78205128 0.78205128\n",
      " 0.78205128 0.78205128 0.78205128 0.76923077 0.76923077 0.76923077\n",
      " 0.75641026 0.74358974 0.73076923 0.71794872 0.70512821 0.69230769\n",
      " 0.67948718 0.66666667 0.65384615 0.64102564 0.62820513 0.61538462\n",
      " 0.6025641  0.58974359 0.57692308 0.56410256 0.55128205 0.53846154\n",
      " 0.52564103 0.51282051 0.5        0.48717949 0.47435897 0.46153846\n",
      " 0.44871795 0.43589744 0.42307692 0.41025641 0.3974359  0.38461538\n",
      " 0.37179487 0.35897436 0.34615385 0.33333333 0.32051282 0.30769231\n",
      " 0.29487179 0.28205128 0.26923077 0.25641026 0.24358974 0.23076923\n",
      " 0.21794872 0.20512821 0.19230769 0.17948718 0.16666667 0.15384615\n",
      " 0.14102564 0.12820513 0.11538462 0.1025641  0.08974359 0.07692308\n",
      " 0.06410256 0.05128205 0.03846154 0.02564103 0.01282051 0.        ]\n",
      "\n",
      "\n",
      "Average Precision Scores\n",
      "\n",
      "{'block': 0.9155208946093999,\n",
      " 'flicker': 0.5866166247763965,\n",
      " 'freeze': 0.3356803293111978,\n",
      " 'freeze_skip': 0.3059837993465002,\n",
      " 'split_horizontal': 0.867548946697728}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score, precision_score,f1_score\n",
    "from sklearn.metrics import auc, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.visutils.plot as vplot\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import pyworld.toolkit.tools.fileutils as fu\n",
    "import pyworld.toolkit.tools.datautils as du\n",
    "\n",
    "\n",
    "import numpy as n\n",
    "from pprint import pprint\n",
    "\n",
    "def roc(label, score):\n",
    "    assert label.shape[0] == score.shape[0]\n",
    "    fpr, tpr, _ = roc_curve(label, score)\n",
    "   \n",
    "    return fpr, tpr\n",
    "\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = {}\n",
    "avg_precs = {}\n",
    "legend = []\n",
    "for i in range(len(a_episodes[:-1])):\n",
    "    episode = a_episodes[i]\n",
    "    anomaly = anoms[i][0]\n",
    "    label = a_tlabels[i]\n",
    "\n",
    "    z, score = distance(model, episode)\n",
    "    latent_space = tu.to_numpy(z)\n",
    "    score = du.normalise(score)\n",
    "    fpr, tpr, _ = roc_curve(label, score)\n",
    "    aucs[anomaly] = auc(fpr, tpr)\n",
    "    prec, rec, _ = precision_recall_curve(label,score)\n",
    "    avg_precs[anomaly] = average_precision_score(label,score)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    legend.append(anomaly)\n",
    "    print(\"\\nEpisode\", i)\n",
    "    print(anomaly)\n",
    "    print(\"\\nAvg Precision Score:\\n\",avg_precs[anomaly])\n",
    "    print(\"\\nPrecision:\\n\",prec)\n",
    "    print(\"\\nRecall:\\n\",rec)\n",
    "    \n",
    "    #print(\"\\nConfusion Matrix:\\n\",confusion_matrix(label,score))\n",
    "    #print(\"\\nRecall\\n\",recall_score(label,score))\n",
    "    #print(\"\\nPrecision\\n\",precision_score(label,score))\n",
    "    #print(\"\\nF1Score\\n\",f1_score(label,score))\n",
    "\n",
    "\n",
    "print(\"\\n\\nAverage Precision Scores\\n\")    \n",
    "pprint(avg_precs)\n",
    "# legend[0] = 'flicker'\n",
    "# legend[1] = 'visual artefact'\n",
    "# legend = [l.replace('_', ' ') for l in legend]\n",
    "# print(legend)\n",
    "\n",
    "# plot = J.plot(fprs, tprs, legend=legend, show=False)\n",
    "# plot.fig.update_layout(showlegend=True, autosize=False, width=500, height=400, margin=dict(l=5,b=5,r=5,t=5))\n",
    "# plot.fig.update_layout(dict(legend=dict(xanchor='center', x=0.5, orientation='h')))\n",
    "\n",
    "#path = \"/home/ben/Downloads/rocs/\"\n",
    "#plot.fig.write_image(path + \"{0}.png\".format(env))\n",
    "#fu.save(path + \"{0}.json\".format(env), aucs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m auc, confusion_matrix, precision_recall_fscore_support\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mRecall\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,precision_recall_fscore_support(label,score))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc, confusion_matrix, precision_recall_fscore_support\n",
    "print(\"\\nRecall\\n\",precision_recall_fscore_support(label,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_steps = 100\n",
    "batch_size = 256\n",
    "num_classes = 2\n",
    "\n",
    "# Logistic regression (Wx + b).\n",
    "def logistic_regression(x):\n",
    "    # Apply sigmoid to normalize the logits to a probability distribution.\n",
    "    return tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# Calculate cross entropy\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # Encode label to a one hot vector.\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    # Compute cross-entropy.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "\n",
    "# the RMSprop optimizer with the default hyper-parameters\n",
    "optimizer = tf.optimizers.legacy.RMSprop(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "  # Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n",
    "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "from sklearn.metrics import auc, confusion_matrix\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# Run training for the given number of steps.\n",
    "k=1\n",
    "fprs = []\n",
    "tprs = []\n",
    "aucs = {}\n",
    "\n",
    "for i in range(len(a_episodes[:-1])):\n",
    "\n",
    "    episode = a_episodes[i]\n",
    "    anomaly = anoms[i][0]\n",
    "    label = a_tlabels[i]\n",
    "    latent_space, score = distance(model, episode)\n",
    "\n",
    "    score1 = score.reshape(score.shape[0],1)\n",
    "    x = tf.concat([latent_space[1:], score1], axis=1)\n",
    "    W = tf.Variable(tf.ones([x.shape[1], 1]), name=\"weight\")\n",
    "    b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "\n",
    "    for step in range(training_steps):\n",
    "        # Run the optimization to update W and b values.\n",
    "        run_optimization(x, label)     \n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, label)\n",
    "        accur = accuracy(pred, label)\n",
    "            \n",
    "    fpr, tpr, _ = roc_curve(label, pred)\n",
    "    aucs[anomaly] = auc(fpr, tpr)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    #print(\"eposide: \",i, \"loss: \",loss, \"score: \",pred)\n",
    "print(\"Auc after active learning: \",aucs)\n",
    "\n",
    "# images = T.HWC(tu.to_numpy(episode))\n",
    "# up_label = []\n",
    "# up_episode = []\n",
    "# top_k = np.argsort(pred)\n",
    "# for j in range(k):\n",
    "#     J.images(images[top_k[j]])\n",
    "\n",
    "#     feedback = input(\"Is this a valid anomaly? [y/n]\")\n",
    "#     if feedback.lower() == 'y':\n",
    "#         up_label.append(1)\n",
    "#     else:\n",
    "#         up_label.append(0)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms[0] = ('flicker', anoms[1])\n",
    "anoms[1] = ('visual artefact', anoms[1])\n",
    "anoms = [(a[0].replace('_',' '), a[1]) for a in anoms]\n",
    "for a in anoms:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.visutils.plot as vplot\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import pyworld.toolkit.tools.datautils as du\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "subplot = plotly.subplots.make_subplots(rows=3,cols=2, vertical_spacing = 0.08, horizontal_spacing = 0.05, subplot_titles=[a[0] for a in anoms[:-1]])\n",
    "\n",
    "\n",
    "\n",
    "showlegend = True\n",
    "\n",
    "def histogram(model, episode, labels, title, i, j, bins=50):\n",
    "    z, d = distance(model, episode)\n",
    "    d = du.normalise(d)\n",
    "    \n",
    "    d_a = d[labels==1]\n",
    "    d_n = d[labels==0]\n",
    "    print(d.shape, d_a.shape, d_n.shape)\n",
    "    binsize = (np.max(d) - np.min(d)) / bins\n",
    "    print(\"anomaly count: \", d_a.shape[0], \"normal count: \", d_n.shape[0])\n",
    "    subplot.add_trace(go.Histogram(x=d_a, marker=dict(color='red'), name='anomaly', showlegend=showlegend, xbins=dict(size=binsize)), row=i, col=j)\n",
    "    subplot.add_trace(go.Histogram(x=d_n, marker=dict(color='blue'), name='normal', showlegend=showlegend, xbins=dict(size=binsize)), row=i, col=j)\n",
    "\n",
    "histogram(model, a_episodes[0], a_tlabels[0], anoms[0], 1, 1)\n",
    "showlegend=False\n",
    "histogram(model, a_episodes[1], a_tlabels[1], anoms[1], 1, 2)\n",
    "histogram(model, a_episodes[2], a_tlabels[2], anoms[2], 2, 1)\n",
    "histogram(model, a_episodes[3], a_tlabels[3], anoms[3], 2, 2)\n",
    "histogram(model, a_episodes[4], a_tlabels[4], anoms[4], 3, 1)\n",
    "histogram(model, a_episodes[5], a_tlabels[5], anoms[5], 3, 2)\n",
    "\n",
    "subplot.update_layout(yaxis_type=\"log\")\n",
    "subplot.update_layout(yaxis2_type=\"log\")\n",
    "subplot.update_layout(yaxis3_type=\"log\")\n",
    "subplot.update_layout(yaxis4_type=\"log\")\n",
    "subplot.update_layout(yaxis5_type=\"log\")\n",
    "subplot.update_layout(yaxis6_type=\"log\")\n",
    "#print(subplot)\n",
    "subplot.update_layout(margin=dict(l=5,b=0,r=5,t=20))\n",
    "subplot.update_layout(dict(legend=dict(xanchor='center', y = -0.03, x=0.5, orientation='h')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert config.latent_shape == 2 #otherwise... hmmm\n",
    "print(config.latent_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Graphs\n",
    "Distance graphs are interactive and show the score (naturaly ordered) of each transition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "def plot_distance(model, episode):\n",
    "    z, d = distance(model, episode)\n",
    "    images = T.HWC(tu.to_numpy(episode))\n",
    "\n",
    "    plot = J.SimplePlot(np.arange(len(d)), d)\n",
    "    image1 = J.SimpleImage(images[0])\n",
    "    image2 = J.SimpleImage(images[1])\n",
    "\n",
    "    def on_hover(trace, points, state):\n",
    "        i = points.point_inds[0]\n",
    "        image1.set_image(images[i])\n",
    "        image2.set_image(images[i+1])\n",
    "\n",
    "    plot.on_hover(on_hover)\n",
    "    d_images = J.layout_horizontal(image1.fig, image2.fig)\n",
    "    d_plot = J.layout_horizontal(plot.fig)\n",
    "    J.display(J.layout_vertical(d_plot, d_images))\n",
    "\n",
    "env = \"Pong\"\n",
    "dataset = datasets.dataset('aad.raw.{0}'.format(env))\n",
    "dataset.state.transform.to_float().CHW().torch()\n",
    "episode = [x for x in dataset.state.load(1)][0]\n",
    "plot_distance(model, episode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "import numpy as np\n",
    "\n",
    "for i in range(len(a_episodes)):\n",
    "    a = anoms[i][0]\n",
    "    print(a)\n",
    "    J.images(T.HWC(tu.to_numpy(a_episodes[i])))\n",
    "    \n",
    "    #J.scatter(np.arange(len(a_labels[i])), a_labels[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and show old 2D visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from types import SimpleNamespace\n",
    "import anomapy.train.sssn as sssn\n",
    "import pyworld.toolkit.tools.wbutils as wbu\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "#load model\n",
    "env = \"Breakout\"\n",
    "run = \"benedict-wilkins/anomapy/sssn-Breakout-20200209131829\"\n",
    "models, config = wbu.load(run)\n",
    "config['state'] = dict(shape=config['state_shape'])\n",
    "model = models['model.pt'].load(sssn.model(**config))\n",
    "config = SimpleNamespace(**config)\n",
    "\n",
    "#load data\n",
    "num_episodes = 1\n",
    "dataset = datasets.dataset('aad.raw.{0}'.format(env))\n",
    "dataset.state.transform.to_float().CHW().torch()\n",
    "episodes = [x for x in dataset.state.load(num_episodes)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "import anomapy.train.sssn as sssn\n",
    "import pyworld.toolkit.tools.visutils.transform as T\n",
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.torchutils as tu\n",
    "\n",
    "a = 5\n",
    "episode = a_episodes[a]\n",
    "labels = a_labels[a].astype(np.uint8)\n",
    "print(labels)\n",
    "\n",
    "def plot_latent(model, episode):\n",
    "    z = tu.to_numpy(sssn.encode(model, episode))\n",
    "    images = T.HWC(tu.to_numpy(episode))\n",
    "    return J.scatter_image(z[:,0], z[:,1], images, scatter_colour=np.array(['blue','red'])[labels], line_colour='#b9d1fa', scale=1.5)\n",
    "\n",
    "from ipywidgets import Image, Layout, VBox, HBox, interact, IntSlider, IntProgress, HTML, Output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "fig, image = plot_latent(model, episode)\n",
    "\n",
    "fig.update_layout(width=600, height=500)\n",
    "#box_layout = widgets.Layout(display='flex',flex_flow='row',align_items='center',width='100%',height='100%')\n",
    "#display(HBox([fig], layout=box_layout))\n",
    "\n",
    "#box_layout = widgets.Layout(display='flex',flex_flow='row',align_items='center',width='100%',height='100%')\n",
    "#display(HBox([fig, image_widget], layout=box_layout)) #basically... this needs to be done in jupyter..?!]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "-----------------\n",
    "-----------------\n",
    "\n",
    "# OTHER DEMOS\n",
    "\n",
    "\n",
    "#### dynamic plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "loss_plot = J.dynamic_plot(update_after=100)\n",
    "\n",
    "for i in range(1000):\n",
    "    time.sleep(0.01)\n",
    "    loss_plot.update(i, np.sin(i/(np.pi*2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "z = tu.to_numpy(tf.keras.optimiser.encode(episode))\n",
    "images = T.HWC(tu.to_numpy(episode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(1000)\n",
    "y = np.sin(x)\n",
    "\n",
    "plot = J.SimplePlot(x,y)\n",
    "def on_hover(trace, points, state):\n",
    "    ind = points.point_inds[0]\n",
    "    print(ind)\n",
    "    \n",
    "plot.on_hover(on_hover)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive plot with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import numpy as np\n",
    "\n",
    "N = 100\n",
    "x = np.arange(N)\n",
    "y = np.sin(x)\n",
    "images = np.random.randint(0,255,size=(N, 100, 100, 3))\n",
    "image = J.SimpleImage(images[0])\n",
    "\n",
    "plot = J.SimplePlot(x,y)\n",
    "def on_hover(trace, points, state):\n",
    "    i = points.point_inds[0]\n",
    "    image.set_image(images[i])\n",
    "    \n",
    "plot.on_hover(on_hover)\n",
    "\n",
    "J.display(J.layout_horizontal(plot.fig, image.fig))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sliding Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import pyworld.toolkit.tools.visutils.plot as vplot\n",
    "import numpy as np\n",
    "\n",
    "N = 100\n",
    "x = np.arange(N)\n",
    "y = np.sin(x)\n",
    "yc = np.random.uniform(0,1,size=y.shape[0])\n",
    "\n",
    "fig = J.histogram([y,yc], show=False)\n",
    "vplot.histogram_slider(fig, sizes=np.arange(0.01,0.5,0.01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 100\n",
    "x = np.arange(N)\n",
    "y = np.sin(x)\n",
    "yc = np.random.uniform(0,1,size=y.shape[0])\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def hist(x, color, name, showlegend=False):\n",
    "    return go.Histogram(x=x, marker=dict(color=color), name=name, showlegend=showlegend)\n",
    "\n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "\n",
    "\n",
    "subplot = plotly.subplots.make_subplots(rows=3, cols=2)\n",
    "trace1 = subplot.add_trace(hist(x, c1, 'anomaly', showlegend=True), row=1, col=1)\n",
    "trace2 = subplot.add_trace(hist(y, c2, 'normal', showlegend=True), row=1, col=1)\n",
    "trace3 = subplot.add_trace(hist(yc, c1, 'anomaly'), row=1, col=2)\n",
    "\n",
    "subplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change scatter colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyworld.toolkit.tools.visutils.jupyter as J\n",
    "import numpy as np\n",
    "\n",
    "n = 10\n",
    "x = np.arange(n)\n",
    "y = np.sin(x)\n",
    "\n",
    "plot = J.SimplePlot(x,y,mode=J.line_mode.marker)\n",
    "def on_hover(trace, points, state):\n",
    "    ind = points.point_inds[0]\n",
    "    print(ind)\n",
    "    \n",
    "plot.on_hover(on_hover)\n",
    "#print(plot.fig)\n",
    "plot.fig.data[0]['marker'] = dict(color=np.random.randint(0,3,size=n).tolist())\n",
    "plot.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a122bbce8198f2764ba6b4ebbf02b86ac09bb402d4dbc30035aa408feb53486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
